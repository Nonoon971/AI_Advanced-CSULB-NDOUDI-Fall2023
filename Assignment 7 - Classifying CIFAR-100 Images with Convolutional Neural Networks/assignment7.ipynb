{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c5a571-f8a5-480f-a7bc-c140e2a993d1",
   "metadata": {},
   "source": [
    "# Assignment 7 \n",
    "*<span style=\"float:right;\">Norine NDOUDI</span>*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7048ed53-8030-4940-a17d-0d325719dc25",
   "metadata": {},
   "source": [
    "### Generation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be4d23d5-7f1b-48aa-8448-e63416529e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "\n",
    "# Load the training data\n",
    "with open('cifar-100-python/cifar-100-python/train', 'rb') as fo:\n",
    "    trainEntire_dataset = pickle.load(fo, encoding='bytes')\n",
    "\n",
    "# Load the test data\n",
    "with open('cifar-100-python/cifar-100-python/test', 'rb') as fo:\n",
    "    testEntire_dataset = pickle.load(fo, encoding='bytes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daebf72c-5cf9-41e1-870d-09a3d57093b1",
   "metadata": {},
   "source": [
    "### Data Division & Label Prediction Requirement\n",
    "We will divide the training dataset into two parts: a sub-\n",
    "training set and a validation set  \n",
    "We are exclusively focus on the \"fine\" labels and not the coarse ones. That's why, we will only get back the `b'fine_labels'` elements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ff0545-c6f3-441d-a87d-a81dfcb6c81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Spliting dataset into training, validation and allocate 1/5 of the training dataset as the validation set randomly\n",
    "train_data, valid_data, train_labels, valid_labels = train_test_split(trainEntire_dataset[b'data'], trainEntire_dataset[b'fine_labels'], test_size=1/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e1ad9c3-255b-4101-992b-00b0b2d78d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 3072)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd968b5-5715-4e15-8f61-becde7e8d7f5",
   "metadata": {},
   "source": [
    "The training and validation data have a shape of (40000, 3072) instead of being in the form of 32x32x3 matrices. The number 3072 stands for the calculation of $ 32 \\times 32 \\times 3$. Therefore, we'll reshape the data to have the correct format (40000, 32, 32, 3) that we need to create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62c4c7ce-7088-4704-8309-a1fc49f3239e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.reshape(-1, 32, 32, 3)\n",
    "valid_data = valid_data.reshape(-1, 32, 32, 3)\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261e96cd-c84b-4b44-83bf-89eff47b52fb",
   "metadata": {},
   "source": [
    "### Model Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af085c3e-5624-421a-9e2d-15b4185e2ca5",
   "metadata": {},
   "source": [
    "We need to vectorize the labels. In fact, `train_labels` contains an integer label for each image. Each label corresponds to one of the 100 classes in the CIFAR-100 dataset. For example, if train_labels[i] is 1, it means that the image at index i in the train_data array belongs to class 1 over the 100 classes.  \n",
    "So, we will use the one-hot encoding method to embed each label as an all-zero vector with a 1 in the place of the label index with the `to_categorical` Keras function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2470460-7df1-4b94-845b-dc07a4fd92a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_labels_encoding = to_categorical(train_labels, 100)\n",
    "valid_labels_encoding = to_categorical(valid_labels, 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c31a6f-d8cb-47ca-8700-e8b54b922670",
   "metadata": {},
   "source": [
    "For a Deep Neural Network, we should normalize the image pixel data. To do so, we will divide the image pixel values by 255 to scale them to a range from 0 to 1.  \n",
    "That way, we will obtain small numbers (instead of a high numeric value) and the computation will become easier and faster.\n",
    "*<span style=\"float:right\">[Source page](https://medium.com/analytics-vidhya/a-tip-a-day-python-tip-8-why-should-we-normalize-image-pixel-values-or-divide-by-255-4608ac5cd26a#:~:text=When%20using%20the%20image%20as,computation%20becomes%20easier%20and%20faster.)</span>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54e84e88-2344-4c1f-9a17-38a22e2df51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize training dta\n",
    "train_data_normalized = train_data / 255.0\n",
    "\n",
    "# Normalize validation data\n",
    "valid_data_normalized = valid_data / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7abe882-6180-4a84-9459-31c564f85503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do the same for the test data\n",
    "test_data = testEntire_dataset[b'data']\n",
    "test_data = test_data.reshape(-1, 32, 32, 3)\n",
    "test_labels = testEntire_dataset[b'fine_labels']\n",
    "test_labels_encoding = to_categorical(test_labels, 100)\n",
    "testEntire_normalized = test_data / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4207a7-1c9a-4e9f-8eef-a6f3e0f646cd",
   "metadata": {},
   "source": [
    "For **image classification** of CIFAR-100, we will use a Convolutional Neural Network. We will experiment CNN models with different architectures, hyperparameters, to find 3 models that work best for the problem.  \n",
    "The last layer uses a **softmax** function activation. In that case, the network will output a probability distribution over the 100 different output classes. That is to say it will produce a 100-dimensional output vector, where output[i] is the probability that the sample belongs to class i."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28bdf36-3c27-4e4b-b726-5df480f2d12b",
   "metadata": {},
   "source": [
    "For the first model, I just take the inspiration from the assignment 6 with less convolutional layers and the softmax function for the last layers as explained above.  \n",
    "After several tests with different epochs, the first model undergoes overfitting after 8 epochs so finally, we will train this model for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa6977f6-32ad-46d9-9690-19a948dbd3bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 57s 41ms/step - loss: 3.8773 - accuracy: 0.1177 - val_loss: 3.4642 - val_accuracy: 0.1851\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 52s 41ms/step - loss: 3.2790 - accuracy: 0.2171 - val_loss: 3.1808 - val_accuracy: 0.2336\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 52s 41ms/step - loss: 3.0216 - accuracy: 0.2623 - val_loss: 3.0235 - val_accuracy: 0.2603\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 51s 41ms/step - loss: 2.8453 - accuracy: 0.2969 - val_loss: 2.9955 - val_accuracy: 0.2691\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 53s 42ms/step - loss: 2.7121 - accuracy: 0.3246 - val_loss: 2.9607 - val_accuracy: 0.2795\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 54s 43ms/step - loss: 2.6003 - accuracy: 0.3450 - val_loss: 2.8926 - val_accuracy: 0.2922\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 57s 46ms/step - loss: 2.5003 - accuracy: 0.3650 - val_loss: 2.8730 - val_accuracy: 0.3018\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 62s 49ms/step - loss: 2.4094 - accuracy: 0.3854 - val_loss: 2.8729 - val_accuracy: 0.2983\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 56s 45ms/step - loss: 2.3270 - accuracy: 0.4008 - val_loss: 2.8911 - val_accuracy: 0.2978\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 55s 44ms/step - loss: 2.2488 - accuracy: 0.4172 - val_loss: 2.8959 - val_accuracy: 0.2982\n"
     ]
    }
   ],
   "source": [
    "### Building the neural network\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "#Model 1\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='softmax'))  # 100 classes for CIFAR-100\n",
    "\n",
    "# Compile the model with Adam Optimizer\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data_normalized, train_labels_encoding, epochs=10, validation_data=(valid_data_normalized, valid_labels_encoding))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e27acd97-2441-4545-84e1-ac347cf66873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 10ms/step - loss: 2.8990 - accuracy: 0.3068\n",
      " Test loss: 2.8989667892456055, Test accuracy: 0.3068000078201294\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(testEntire_normalized, test_labels_encoding)\n",
    "print(f' Test loss: {test_loss}, Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1441792b-b16c-4aab-b04e-eff36f38a439",
   "metadata": {},
   "source": [
    "For the second model, we took the same architecture but we have changed the activation function of the layers (tanh instead of relu). We have also increased the weights of the convolutional layers and reduce the one of the Dense layer.  \n",
    "We add a batch size and personalize the Adam optimizer by specify the hyperparameters beta values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbddfe90-2a04-4b36-bd3c-8c3a3073df6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "79/79 [==============================] - 78s 962ms/step - loss: 4.1646 - accuracy: 0.0821 - val_loss: 3.8209 - val_accuracy: 0.1341\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 78s 982ms/step - loss: 3.6212 - accuracy: 0.1718 - val_loss: 3.5188 - val_accuracy: 0.1866\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 78s 982ms/step - loss: 3.3643 - accuracy: 0.2167 - val_loss: 3.3280 - val_accuracy: 0.2153\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 80s 1s/step - loss: 3.1813 - accuracy: 0.2494 - val_loss: 3.1969 - val_accuracy: 0.2385\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 78s 988ms/step - loss: 3.0336 - accuracy: 0.2769 - val_loss: 3.1138 - val_accuracy: 0.2570\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 77s 981ms/step - loss: 2.9152 - accuracy: 0.2988 - val_loss: 3.0340 - val_accuracy: 0.2679\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 78s 982ms/step - loss: 2.7983 - accuracy: 0.3217 - val_loss: 2.9920 - val_accuracy: 0.2747\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 78s 992ms/step - loss: 2.6906 - accuracy: 0.3443 - val_loss: 2.9369 - val_accuracy: 0.2866\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 78s 984ms/step - loss: 2.5905 - accuracy: 0.3654 - val_loss: 2.9200 - val_accuracy: 0.2863\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 79s 995ms/step - loss: 2.5032 - accuracy: 0.3832 - val_loss: 2.8868 - val_accuracy: 0.2942\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 78s 986ms/step - loss: 2.3958 - accuracy: 0.4091 - val_loss: 2.8458 - val_accuracy: 0.3073\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 78s 987ms/step - loss: 2.3084 - accuracy: 0.4290 - val_loss: 2.9180 - val_accuracy: 0.2904\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 81s 1s/step - loss: 2.2180 - accuracy: 0.4474 - val_loss: 2.8246 - val_accuracy: 0.3108\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 79s 998ms/step - loss: 2.1191 - accuracy: 0.4717 - val_loss: 2.8089 - val_accuracy: 0.3128\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 79s 996ms/step - loss: 2.0222 - accuracy: 0.4940 - val_loss: 2.8296 - val_accuracy: 0.3079\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 79s 999ms/step - loss: 1.9320 - accuracy: 0.5156 - val_loss: 2.8471 - val_accuracy: 0.3090\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 78s 989ms/step - loss: 1.8475 - accuracy: 0.5362 - val_loss: 2.8348 - val_accuracy: 0.3145\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 78s 986ms/step - loss: 1.7458 - accuracy: 0.5622 - val_loss: 2.9160 - val_accuracy: 0.3038\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 78s 984ms/step - loss: 1.6708 - accuracy: 0.5792 - val_loss: 2.8844 - val_accuracy: 0.3089\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 78s 983ms/step - loss: 1.5728 - accuracy: 0.6097 - val_loss: 2.9605 - val_accuracy: 0.2964\n"
     ]
    }
   ],
   "source": [
    "# Model 2\n",
    "# Get back the original data befor training\n",
    "\n",
    "train_labels_encoding = to_categorical(train_labels, 100)\n",
    "valid_labels_encoding = to_categorical(valid_labels, 100)\n",
    "\n",
    "train_data_normalized = train_data / 255.0\n",
    "valid_data_normalized = valid_data / 255.0\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='tanh', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='tanh'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='tanh'))\n",
    "model.add(layers.Dense(100, activation='softmax'))  # 100 classes for CIFAR-100\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_data_normalized, train_labels_encoding, epochs=20, batch_size=512, validation_data=(valid_data_normalized, valid_labels_encoding))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0deacd2-5abd-4eba-9c76-0fbf94189db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 19ms/step - loss: 2.9505 - accuracy: 0.3027\n",
      " Test loss: 2.9504668712615967, Test accuracy: 0.302700012922287\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(testEntire_normalized, test_labels_encoding)\n",
    "print(f' Test loss: {test_loss}, Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a18cbd8-73da-45ae-b36a-f25a6c32a5ea",
   "metadata": {},
   "source": [
    "Same for the third one, we have the more or less the same architecture as the first model but we change the optimizer for the rmsprop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbee3475-b8d9-45f4-8c20-5099ef881bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 57s 45ms/step - loss: 4.2841 - accuracy: 0.0597 - val_loss: 3.8497 - val_accuracy: 0.1126\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 51s 41ms/step - loss: 3.8119 - accuracy: 0.1265 - val_loss: 3.7286 - val_accuracy: 0.1369\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 52s 42ms/step - loss: 3.7779 - accuracy: 0.1364 - val_loss: 3.7281 - val_accuracy: 0.1440\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 52s 42ms/step - loss: 3.7709 - accuracy: 0.1362 - val_loss: 3.8334 - val_accuracy: 0.1398\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 55s 44ms/step - loss: 3.7831 - accuracy: 0.1338 - val_loss: 3.8152 - val_accuracy: 0.1323\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 57s 45ms/step - loss: 3.7985 - accuracy: 0.1303 - val_loss: 4.0030 - val_accuracy: 0.0866\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 54s 43ms/step - loss: 3.8073 - accuracy: 0.1268 - val_loss: 3.8189 - val_accuracy: 0.1258\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 54s 43ms/step - loss: 3.8125 - accuracy: 0.1246 - val_loss: 3.7315 - val_accuracy: 0.1351\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 54s 44ms/step - loss: 3.7970 - accuracy: 0.1286 - val_loss: 3.9509 - val_accuracy: 0.0960\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 53s 42ms/step - loss: 3.7941 - accuracy: 0.1299 - val_loss: 3.8483 - val_accuracy: 0.1235\n"
     ]
    }
   ],
   "source": [
    "# Model 3 with rmsprop optimizer\n",
    "train_labels_encoding = to_categorical(train_labels, 100)\n",
    "valid_labels_encoding = to_categorical(valid_labels, 100)\n",
    "\n",
    "train_data_normalized = train_data / 255.0\n",
    "valid_data_normalized = valid_data / 255.0\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='softmax'))  # 100 classes for CIFAR-100\n",
    "model.compile(optimizer=optimizers.RMSprop(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_data_normalized, train_labels_encoding, epochs=10, validation_data=(valid_data_normalized, valid_labels_encoding))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b72b394-5548-45b4-802a-ed723c6ef8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 11ms/step - loss: 3.8565 - accuracy: 0.1267\n",
      " Test loss: 3.856492519378662, Test accuracy: 0.1266999989748001\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(testEntire_normalized, test_labels_encoding)\n",
    "print(f' Test loss: {test_loss}, Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b1d87a-a9e0-47ab-9120-772c4b4492f7",
   "metadata": {},
   "source": [
    "For the fourth model, we added one convulotional layer and a dropout regularization with a probability of 0.5 to do something against overfitting we got before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bcda091-cc5b-46d2-b64b-23cf8b5e1acf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "157/157 [==============================] - 44s 259ms/step - loss: 4.3854 - accuracy: 0.0366 - val_loss: 4.0060 - val_accuracy: 0.0880\n",
      "Epoch 2/40\n",
      "157/157 [==============================] - 43s 274ms/step - loss: 3.8953 - accuracy: 0.1002 - val_loss: 3.7255 - val_accuracy: 0.1279\n",
      "Epoch 3/40\n",
      "157/157 [==============================] - 40s 252ms/step - loss: 3.6724 - accuracy: 0.1366 - val_loss: 3.5249 - val_accuracy: 0.1704\n",
      "Epoch 4/40\n",
      "157/157 [==============================] - 41s 259ms/step - loss: 3.5144 - accuracy: 0.1644 - val_loss: 3.4297 - val_accuracy: 0.1845\n",
      "Epoch 5/40\n",
      "157/157 [==============================] - 43s 277ms/step - loss: 3.3932 - accuracy: 0.1859 - val_loss: 3.2934 - val_accuracy: 0.2142\n",
      "Epoch 6/40\n",
      "157/157 [==============================] - 40s 253ms/step - loss: 3.2948 - accuracy: 0.2041 - val_loss: 3.2005 - val_accuracy: 0.2243\n",
      "Epoch 7/40\n",
      "157/157 [==============================] - 40s 254ms/step - loss: 3.2144 - accuracy: 0.2193 - val_loss: 3.1625 - val_accuracy: 0.2297\n",
      "Epoch 8/40\n",
      "157/157 [==============================] - 43s 276ms/step - loss: 3.1480 - accuracy: 0.2290 - val_loss: 3.0916 - val_accuracy: 0.2448\n",
      "Epoch 9/40\n",
      "157/157 [==============================] - 40s 252ms/step - loss: 3.0793 - accuracy: 0.2463 - val_loss: 3.0578 - val_accuracy: 0.2537\n",
      "Epoch 10/40\n",
      "157/157 [==============================] - 40s 256ms/step - loss: 3.0193 - accuracy: 0.2548 - val_loss: 3.0215 - val_accuracy: 0.2566\n",
      "Epoch 11/40\n",
      "157/157 [==============================] - 45s 285ms/step - loss: 2.9666 - accuracy: 0.2650 - val_loss: 3.0178 - val_accuracy: 0.2593\n",
      "Epoch 12/40\n",
      "157/157 [==============================] - 44s 283ms/step - loss: 2.9115 - accuracy: 0.2758 - val_loss: 2.9564 - val_accuracy: 0.2667\n",
      "Epoch 13/40\n",
      "157/157 [==============================] - 45s 290ms/step - loss: 2.8674 - accuracy: 0.2849 - val_loss: 2.9481 - val_accuracy: 0.2783\n",
      "Epoch 14/40\n",
      "157/157 [==============================] - 44s 280ms/step - loss: 2.8358 - accuracy: 0.2923 - val_loss: 2.9087 - val_accuracy: 0.2805\n",
      "Epoch 15/40\n",
      "157/157 [==============================] - 40s 258ms/step - loss: 2.7763 - accuracy: 0.3024 - val_loss: 2.9050 - val_accuracy: 0.2851\n",
      "Epoch 16/40\n",
      "157/157 [==============================] - 43s 275ms/step - loss: 2.7468 - accuracy: 0.3066 - val_loss: 2.9017 - val_accuracy: 0.2865\n",
      "Epoch 17/40\n",
      "157/157 [==============================] - 41s 260ms/step - loss: 2.6971 - accuracy: 0.3150 - val_loss: 2.8518 - val_accuracy: 0.2940\n",
      "Epoch 18/40\n",
      "157/157 [==============================] - 40s 256ms/step - loss: 2.6482 - accuracy: 0.3265 - val_loss: 2.8403 - val_accuracy: 0.3001\n",
      "Epoch 19/40\n",
      "157/157 [==============================] - 43s 275ms/step - loss: 2.6229 - accuracy: 0.3316 - val_loss: 2.8468 - val_accuracy: 0.2931\n",
      "Epoch 20/40\n",
      "157/157 [==============================] - 42s 267ms/step - loss: 2.5832 - accuracy: 0.3372 - val_loss: 2.7951 - val_accuracy: 0.3040\n",
      "Epoch 21/40\n",
      "157/157 [==============================] - 41s 259ms/step - loss: 2.5557 - accuracy: 0.3424 - val_loss: 2.9026 - val_accuracy: 0.2841\n",
      "Epoch 22/40\n",
      "157/157 [==============================] - 44s 281ms/step - loss: 2.5266 - accuracy: 0.3489 - val_loss: 2.7983 - val_accuracy: 0.3038\n",
      "Epoch 23/40\n",
      "157/157 [==============================] - 41s 261ms/step - loss: 2.4816 - accuracy: 0.3564 - val_loss: 2.8000 - val_accuracy: 0.3071\n",
      "Epoch 24/40\n",
      "157/157 [==============================] - 41s 258ms/step - loss: 2.4505 - accuracy: 0.3629 - val_loss: 2.7670 - val_accuracy: 0.3141\n",
      "Epoch 25/40\n",
      "157/157 [==============================] - 45s 286ms/step - loss: 2.4217 - accuracy: 0.3699 - val_loss: 2.7759 - val_accuracy: 0.3134\n",
      "Epoch 26/40\n",
      "157/157 [==============================] - 41s 258ms/step - loss: 2.3942 - accuracy: 0.3737 - val_loss: 2.7935 - val_accuracy: 0.3098\n",
      "Epoch 27/40\n",
      "157/157 [==============================] - 41s 261ms/step - loss: 2.3656 - accuracy: 0.3802 - val_loss: 2.8439 - val_accuracy: 0.3075\n",
      "Epoch 28/40\n",
      "157/157 [==============================] - 43s 272ms/step - loss: 2.3351 - accuracy: 0.3877 - val_loss: 2.8012 - val_accuracy: 0.3082\n",
      "Epoch 29/40\n",
      "157/157 [==============================] - 41s 262ms/step - loss: 2.3124 - accuracy: 0.3919 - val_loss: 2.7832 - val_accuracy: 0.3208\n",
      "Epoch 30/40\n",
      "157/157 [==============================] - 42s 266ms/step - loss: 2.2874 - accuracy: 0.3946 - val_loss: 2.7924 - val_accuracy: 0.3141\n",
      "Epoch 31/40\n",
      "157/157 [==============================] - 43s 273ms/step - loss: 2.2564 - accuracy: 0.4008 - val_loss: 2.7763 - val_accuracy: 0.3201\n",
      "Epoch 32/40\n",
      "157/157 [==============================] - 41s 261ms/step - loss: 2.2365 - accuracy: 0.4043 - val_loss: 2.7717 - val_accuracy: 0.3169\n",
      "Epoch 33/40\n",
      "157/157 [==============================] - 42s 268ms/step - loss: 2.2035 - accuracy: 0.4099 - val_loss: 2.8018 - val_accuracy: 0.3186\n",
      "Epoch 34/40\n",
      "157/157 [==============================] - 42s 270ms/step - loss: 2.1834 - accuracy: 0.4133 - val_loss: 2.7880 - val_accuracy: 0.3192\n",
      "Epoch 35/40\n",
      "157/157 [==============================] - 42s 265ms/step - loss: 2.1632 - accuracy: 0.4191 - val_loss: 2.7885 - val_accuracy: 0.3271\n",
      "Epoch 36/40\n",
      "157/157 [==============================] - 43s 274ms/step - loss: 2.1307 - accuracy: 0.4234 - val_loss: 2.8181 - val_accuracy: 0.3221\n",
      "Epoch 37/40\n",
      "157/157 [==============================] - 44s 283ms/step - loss: 2.1089 - accuracy: 0.4288 - val_loss: 2.7997 - val_accuracy: 0.3168\n",
      "Epoch 38/40\n",
      "157/157 [==============================] - 42s 269ms/step - loss: 2.0835 - accuracy: 0.4331 - val_loss: 2.8377 - val_accuracy: 0.3139\n",
      "Epoch 39/40\n",
      "157/157 [==============================] - 44s 281ms/step - loss: 2.0646 - accuracy: 0.4412 - val_loss: 2.8453 - val_accuracy: 0.3182\n",
      "Epoch 40/40\n",
      "157/157 [==============================] - 42s 270ms/step - loss: 2.0351 - accuracy: 0.4448 - val_loss: 2.8315 - val_accuracy: 0.3196\n"
     ]
    }
   ],
   "source": [
    "#model 4\n",
    "from keras.layers import Dropout\n",
    "train_labels_encoding = to_categorical(train_labels, 100)\n",
    "valid_labels_encoding = to_categorical(valid_labels, 100)\n",
    "\n",
    "train_data_normalized = train_data / 255.0\n",
    "valid_data_normalized = valid_data / 255.0\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(100, activation='softmax'))\n",
    "            \n",
    "# Compile the model with Adam Optimizer\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data_normalized, train_labels_encoding, epochs=40, batch_size=256, validation_data=(valid_data_normalized, valid_labels_encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c8a4f8f-6fb4-4b28-883d-03645ce01aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 12ms/step - loss: 2.8500 - accuracy: 0.3250\n",
      " Test loss: 2.8500149250030518, Test accuracy: 0.32499998807907104\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(testEntire_normalized, test_labels_encoding)\n",
    "print(f' Test loss: {test_loss}, Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "246a5389-e4e5-44a2-8d9a-77a62f58159d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 151s 119ms/step - loss: 4.6230 - accuracy: 0.0093 - val_loss: 4.6096 - val_accuracy: 0.0088\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 151s 121ms/step - loss: 4.6105 - accuracy: 0.0092 - val_loss: 4.6101 - val_accuracy: 0.0090\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 175s 140ms/step - loss: 4.6102 - accuracy: 0.0099 - val_loss: 4.6120 - val_accuracy: 0.0088\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 180s 144ms/step - loss: 4.6103 - accuracy: 0.0095 - val_loss: 4.6099 - val_accuracy: 0.0096\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 182s 145ms/step - loss: 4.6106 - accuracy: 0.0088 - val_loss: 4.6101 - val_accuracy: 0.0092\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 181s 144ms/step - loss: 4.6102 - accuracy: 0.0096 - val_loss: 4.6110 - val_accuracy: 0.0100\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 173s 139ms/step - loss: 4.6104 - accuracy: 0.0099 - val_loss: 4.6102 - val_accuracy: 0.0099\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 183s 147ms/step - loss: 4.6103 - accuracy: 0.0094 - val_loss: 4.6098 - val_accuracy: 0.0098\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 180s 144ms/step - loss: 4.6104 - accuracy: 0.0095 - val_loss: 4.6098 - val_accuracy: 0.0131\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 179s 143ms/step - loss: 4.6104 - accuracy: 0.0095 - val_loss: 4.6099 - val_accuracy: 0.0090\n"
     ]
    }
   ],
   "source": [
    "#model 5\n",
    "train_labels_encoding = to_categorical(train_labels, 100)\n",
    "valid_labels_encoding = to_categorical(valid_labels, 100)\n",
    "\n",
    "train_data_normalized = train_data / 255.0\n",
    "valid_data_normalized = valid_data / 255.0\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(100, activation='softmax'))\n",
    "            \n",
    "# Compile the model with Adam Optimizer\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data_normalized, train_labels_encoding, epochs=10, validation_data=(valid_data_normalized, valid_labels_encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94d1c858-b1c4-472c-80e3-1eacf51b3ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 10s 31ms/step - loss: 4.6084 - accuracy: 0.0100\n",
      " Test loss: 4.60841178894043, Test accuracy: 0.009999999776482582\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(testEntire_normalized, test_labels_encoding)\n",
    "print(f' Test loss: {test_loss}, Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64dc014-cbad-4cd0-84db-d94fc2ab7606",
   "metadata": {},
   "source": [
    "For the sixth model, we have more or less the same achitecture as the second model, but we have set a batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b235dfb2-8ffa-4e82-b07c-d010d83fc9c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "157/157 [==============================] - 57s 355ms/step - loss: 3.8999 - accuracy: 0.1221 - val_loss: 3.4729 - val_accuracy: 0.1869\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 49s 311ms/step - loss: 3.2587 - accuracy: 0.2280 - val_loss: 3.1591 - val_accuracy: 0.2447\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 51s 323ms/step - loss: 2.9714 - accuracy: 0.2845 - val_loss: 2.9868 - val_accuracy: 0.2816\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 50s 318ms/step - loss: 2.7696 - accuracy: 0.3241 - val_loss: 2.9110 - val_accuracy: 0.2891\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 49s 315ms/step - loss: 2.5899 - accuracy: 0.3621 - val_loss: 2.8295 - val_accuracy: 0.3106\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 50s 322ms/step - loss: 2.4232 - accuracy: 0.3970 - val_loss: 2.7802 - val_accuracy: 0.3200\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 49s 312ms/step - loss: 2.2754 - accuracy: 0.4311 - val_loss: 2.7443 - val_accuracy: 0.3295\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 52s 329ms/step - loss: 2.1205 - accuracy: 0.4679 - val_loss: 2.7405 - val_accuracy: 0.3221\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 48s 306ms/step - loss: 1.9619 - accuracy: 0.5065 - val_loss: 2.7496 - val_accuracy: 0.3310\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 50s 319ms/step - loss: 1.8055 - accuracy: 0.5470 - val_loss: 2.7581 - val_accuracy: 0.3284\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 49s 315ms/step - loss: 1.6419 - accuracy: 0.5878 - val_loss: 2.7864 - val_accuracy: 0.3260\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 48s 306ms/step - loss: 1.4905 - accuracy: 0.6328 - val_loss: 2.8211 - val_accuracy: 0.3301\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 53s 337ms/step - loss: 1.3293 - accuracy: 0.6747 - val_loss: 2.8699 - val_accuracy: 0.3209\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 48s 307ms/step - loss: 1.1785 - accuracy: 0.7150 - val_loss: 2.9125 - val_accuracy: 0.3247\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 51s 325ms/step - loss: 1.0319 - accuracy: 0.7576 - val_loss: 2.9740 - val_accuracy: 0.3174\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 48s 304ms/step - loss: 0.8925 - accuracy: 0.8003 - val_loss: 3.0308 - val_accuracy: 0.3137\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 50s 316ms/step - loss: 0.7579 - accuracy: 0.8382 - val_loss: 3.1075 - val_accuracy: 0.3131\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 53s 335ms/step - loss: 0.6442 - accuracy: 0.8702 - val_loss: 3.1741 - val_accuracy: 0.3091\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 49s 310ms/step - loss: 0.5371 - accuracy: 0.9017 - val_loss: 3.2596 - val_accuracy: 0.3042\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 51s 323ms/step - loss: 0.4323 - accuracy: 0.9299 - val_loss: 3.3166 - val_accuracy: 0.3047\n"
     ]
    }
   ],
   "source": [
    "#model 6\n",
    "train_labels_encoding = to_categorical(train_labels, 100)\n",
    "valid_labels_encoding = to_categorical(valid_labels, 100)\n",
    "\n",
    "train_data_normalized = train_data / 255.0\n",
    "valid_data_normalized = valid_data / 255.0\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='tanh', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='tanh'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='tanh'))\n",
    "model.add(layers.Dense(100, activation='softmax'))  # 100 classes for CIFAR-100\n",
    "\n",
    "# Compile the model with Adam Optimizer\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data_normalized, train_labels_encoding, epochs=20, batch_size=256, validation_data=(valid_data_normalized, valid_labels_encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6301caea-096d-4ccd-933a-282d700a02c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 12ms/step - loss: 3.2976 - accuracy: 0.3134\n",
      " Test loss: 3.297576904296875, Test accuracy: 0.313400000333786\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(testEntire_normalized, test_labels_encoding)\n",
    "print(f' Test loss: {test_loss}, Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0827db-d6fd-4423-810e-9273274bfc03",
   "metadata": {},
   "source": [
    "### Top 3 model Selection\n",
    "After several tests on different models by modifying their achitecture, learning rate, optimizer... and evaluate these models with the test data, our **top three models will be model 1, model 4 and 6.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc22e2d-3c09-438b-aae7-05ce91dfcfd6",
   "metadata": {},
   "source": [
    "### Full Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a80bff1-c4af-4400-9ec9-1f162cbce8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 349s 164ms/step - loss: 3.7950 - accuracy: 0.1306\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 277s 177ms/step - loss: 2.9439 - accuracy: 0.2762\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 194s 124ms/step - loss: 2.7822 - accuracy: 0.3106\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 272s 174ms/step - loss: 2.5394 - accuracy: 0.3558\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 218s 140ms/step - loss: 2.4472 - accuracy: 0.3761\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 241s 154ms/step - loss: 2.3632 - accuracy: 0.3917\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 240s 154ms/step - loss: 2.2945 - accuracy: 0.4075\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 240s 153ms/step - loss: 2.2185 - accuracy: 0.4219\n",
      "313/313 [==============================] - 16s 41ms/step - loss: 2.8213 - accuracy: 0.3230\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_34 (Conv2D)          (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPooli  (None, 15, 15, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPooli  (None, 6, 6, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 128)               295040    \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 100)               12900     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 327332 (1.25 MB)\n",
      "Trainable params: 327332 (1.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trainEntire_data = trainEntire_dataset[b'data']\n",
    "trainEntire_labels = trainEntire_dataset[b'fine_labels']\n",
    "trainEntire_data = trainEntire_data.reshape(-1, 32, 32, 3)\n",
    "trainEntire_labels_encoding = to_categorical(trainEntire_labels, 100)\n",
    "trainEntire_normalized = trainEntire_data / 255.0\n",
    "\n",
    "#model 1\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='softmax')) \n",
    "\n",
    "# Compile the model with Adam Optimizer\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(trainEntire_normalized, trainEntire_labels_encoding, epochs=10)\n",
    "\n",
    "test_loss1, test_accuracy1 = model.evaluate(testEntire_normalized, test_labels_encoding)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4509350d-b4fd-4256-bb14-3ecbaab1b5e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "196/196 [==============================] - 202s 872ms/step - loss: 4.3185 - accuracy: 0.0458\n",
      "Epoch 2/40\n",
      "196/196 [==============================] - 186s 947ms/step - loss: 3.8006 - accuracy: 0.1176\n",
      "Epoch 3/40\n",
      "196/196 [==============================] - 192s 978ms/step - loss: 3.5499 - accuracy: 0.1598\n",
      "Epoch 4/40\n",
      "196/196 [==============================] - 167s 855ms/step - loss: 3.3915 - accuracy: 0.1874\n",
      "Epoch 5/40\n",
      "196/196 [==============================] - 151s 771ms/step - loss: 3.2731 - accuracy: 0.2103\n",
      "Epoch 6/40\n",
      "196/196 [==============================] - 171s 874ms/step - loss: 3.1823 - accuracy: 0.2256\n",
      "Epoch 7/40\n",
      "196/196 [==============================] - 183s 935ms/step - loss: 3.0962 - accuracy: 0.2410\n",
      "Epoch 8/40\n",
      "196/196 [==============================] - 177s 900ms/step - loss: 3.0363 - accuracy: 0.2515\n",
      "Epoch 9/40\n",
      "196/196 [==============================] - 169s 861ms/step - loss: 2.9606 - accuracy: 0.2678\n",
      "Epoch 10/40\n",
      "196/196 [==============================] - 196s 997ms/step - loss: 2.9054 - accuracy: 0.2781\n",
      "Epoch 11/40\n",
      "196/196 [==============================] - 575s 3s/step - loss: 2.8523 - accuracy: 0.2913\n",
      "Epoch 12/40\n",
      "196/196 [==============================] - 183s 934ms/step - loss: 2.7915 - accuracy: 0.2998\n",
      "Epoch 13/40\n",
      "196/196 [==============================] - 168s 858ms/step - loss: 2.7550 - accuracy: 0.3033\n",
      "Epoch 14/40\n",
      "196/196 [==============================] - 143s 728ms/step - loss: 2.7070 - accuracy: 0.3156\n",
      "Epoch 15/40\n",
      "196/196 [==============================] - 147s 746ms/step - loss: 2.6685 - accuracy: 0.3225\n",
      "Epoch 16/40\n",
      "196/196 [==============================] - 166s 843ms/step - loss: 2.6243 - accuracy: 0.3295\n",
      "Epoch 17/40\n",
      "196/196 [==============================] - 212s 1s/step - loss: 2.5893 - accuracy: 0.3357\n",
      "Epoch 18/40\n",
      "196/196 [==============================] - 202s 1s/step - loss: 2.5486 - accuracy: 0.3453\n",
      "Epoch 19/40\n",
      "196/196 [==============================] - 178s 909ms/step - loss: 2.4999 - accuracy: 0.3536\n",
      "Epoch 20/40\n",
      "196/196 [==============================] - 233s 1s/step - loss: 2.4664 - accuracy: 0.3606\n",
      "Epoch 21/40\n",
      "196/196 [==============================] - 210s 1s/step - loss: 2.4281 - accuracy: 0.3662\n",
      "Epoch 22/40\n",
      "196/196 [==============================] - 191s 977ms/step - loss: 2.4117 - accuracy: 0.3693\n",
      "Epoch 23/40\n",
      "196/196 [==============================] - 168s 856ms/step - loss: 2.3772 - accuracy: 0.3792\n",
      "Epoch 24/40\n",
      "196/196 [==============================] - 179s 912ms/step - loss: 2.3566 - accuracy: 0.3827\n",
      "Epoch 25/40\n",
      "196/196 [==============================] - 197s 1000ms/step - loss: 2.3177 - accuracy: 0.3892\n",
      "Epoch 26/40\n",
      "196/196 [==============================] - 185s 943ms/step - loss: 2.2919 - accuracy: 0.3952\n",
      "Epoch 27/40\n",
      "196/196 [==============================] - 256s 1s/step - loss: 2.2605 - accuracy: 0.3990\n",
      "Epoch 28/40\n",
      "196/196 [==============================] - 201s 1s/step - loss: 2.2369 - accuracy: 0.4074\n",
      "Epoch 29/40\n",
      "196/196 [==============================] - 148s 756ms/step - loss: 2.2091 - accuracy: 0.4094\n",
      "Epoch 30/40\n",
      "196/196 [==============================] - 201s 1s/step - loss: 2.1785 - accuracy: 0.4154\n",
      "Epoch 31/40\n",
      "196/196 [==============================] - 196s 998ms/step - loss: 2.1685 - accuracy: 0.4177\n",
      "Epoch 32/40\n",
      "196/196 [==============================] - 147s 747ms/step - loss: 2.1340 - accuracy: 0.4285\n",
      "Epoch 33/40\n",
      "196/196 [==============================] - 142s 725ms/step - loss: 2.1130 - accuracy: 0.4303\n",
      "Epoch 34/40\n",
      "196/196 [==============================] - 141s 720ms/step - loss: 2.0904 - accuracy: 0.4334\n",
      "Epoch 35/40\n",
      "196/196 [==============================] - 144s 732ms/step - loss: 2.0741 - accuracy: 0.4361\n",
      "Epoch 36/40\n",
      "196/196 [==============================] - 142s 723ms/step - loss: 2.0430 - accuracy: 0.4449\n",
      "Epoch 37/40\n",
      "196/196 [==============================] - 160s 814ms/step - loss: 2.0183 - accuracy: 0.4497\n",
      "Epoch 38/40\n",
      "196/196 [==============================] - 163s 832ms/step - loss: 2.0000 - accuracy: 0.4522\n",
      "Epoch 39/40\n",
      "196/196 [==============================] - 173s 882ms/step - loss: 1.9769 - accuracy: 0.4571\n",
      "Epoch 40/40\n",
      "196/196 [==============================] - 183s 933ms/step - loss: 1.9589 - accuracy: 0.4598\n",
      "313/313 [==============================] - 31s 87ms/step - loss: 2.7573 - accuracy: 0.3380\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_36 (Conv2D)          (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_36 (MaxPooli  (None, 15, 15, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_37 (MaxPooli  (None, 6, 6, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_38 (MaxPooli  (None, 2, 2, 128)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 100)               51300     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407204 (1.55 MB)\n",
      "Trainable params: 407204 (1.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trainEntire_data = trainEntire_dataset[b'data']\n",
    "trainEntire_labels = trainEntire_dataset[b'fine_labels']\n",
    "trainEntire_data = trainEntire_data.reshape(-1, 32, 32, 3)\n",
    "trainEntire_labels_encoding = to_categorical(trainEntire_labels, 100)\n",
    "trainEntire_normalized = trainEntire_data / 255.0\n",
    "\n",
    "#model 4\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(100, activation='softmax'))\n",
    "            \n",
    "# Compile the model with Adam Optimizer\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(trainEntire_normalized, trainEntire_labels_encoding, epochs=40, batch_size=256)\n",
    "\n",
    "test_loss2, test_accuracy2 = model.evaluate(testEntire_normalized, test_labels_encoding)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f46930d-e012-4655-ae55-eb61f984cf78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "196/196 [==============================] - 297s 1s/step - loss: 3.7394 - accuracy: 0.1471\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 286s 1s/step - loss: 3.0939 - accuracy: 0.2599\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 292s 1s/step - loss: 2.8184 - accuracy: 0.3151\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 296s 2s/step - loss: 2.6142 - accuracy: 0.3559\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 290s 1s/step - loss: 2.4360 - accuracy: 0.3926\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 291s 1s/step - loss: 2.2690 - accuracy: 0.4306\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 297s 2s/step - loss: 2.1046 - accuracy: 0.4693\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 288s 1s/step - loss: 1.9487 - accuracy: 0.5052\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 300s 2s/step - loss: 1.7719 - accuracy: 0.5500\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 288s 1s/step - loss: 1.6062 - accuracy: 0.5935\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 292s 1s/step - loss: 1.4427 - accuracy: 0.6378\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 300s 2s/step - loss: 1.2738 - accuracy: 0.6854\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 288s 1s/step - loss: 1.1165 - accuracy: 0.7280\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 298s 2s/step - loss: 0.9588 - accuracy: 0.7737\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 289s 1s/step - loss: 0.8159 - accuracy: 0.8126\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 297s 2s/step - loss: 0.6842 - accuracy: 0.8524\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 287s 1s/step - loss: 0.5646 - accuracy: 0.8884\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 294s 2s/step - loss: 0.4603 - accuracy: 0.9167\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 293s 1s/step - loss: 0.3731 - accuracy: 0.9408\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 285s 1s/step - loss: 0.2922 - accuracy: 0.9609\n",
      "313/313 [==============================] - 28s 86ms/step - loss: 3.4236 - accuracy: 0.3210\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_41 (Conv2D)          (None, 30, 30, 64)        1792      \n",
      "                                                                 \n",
      " max_pooling2d_41 (MaxPooli  (None, 15, 15, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 13, 13, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_42 (MaxPooli  (None, 6, 6, 128)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 128)               589952    \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 100)               12900     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 678500 (2.59 MB)\n",
      "Trainable params: 678500 (2.59 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trainEntire_data = trainEntire_dataset[b'data']\n",
    "trainEntire_labels = trainEntire_dataset[b'fine_labels']\n",
    "trainEntire_data = trainEntire_data.reshape(-1, 32, 32, 3)\n",
    "trainEntire_labels_encoding = to_categorical(trainEntire_labels, 100)\n",
    "trainEntire_normalized = trainEntire_data / 255.0\n",
    "\n",
    "#model 6\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='tanh', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='tanh'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='tanh'))\n",
    "model.add(layers.Dense(100, activation='softmax'))  # 100 classes for CIFAR-100\n",
    "\n",
    "# Compile the model with Adam Optimizer\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(trainEntire_normalized, trainEntire_labels_encoding, epochs=20, batch_size=256)\n",
    "\n",
    "test_loss3, test_accuracy3 = model.evaluate(testEntire_normalized, test_labels_encoding)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f67b9e90-1696-46a3-aab7-120965173bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 29s 92ms/step\n",
      "Result of the prediction for the second image: \n",
      "[4.04499497e-06 3.11825832e-04 2.03277729e-03 2.91703714e-06\n",
      " 2.78368330e-04 3.95851021e-05 1.42988889e-03 7.07291008e-04\n",
      " 7.19506759e-04 7.77823880e-06 1.93979125e-04 9.37384204e-04\n",
      " 1.45714903e-05 9.17073976e-06 1.02241558e-03 2.76570790e-05\n",
      " 1.17752228e-04 3.18500906e-06 3.92717280e-04 8.12614326e-06\n",
      " 1.24783276e-06 9.33885531e-06 3.89744207e-04 3.14274221e-04\n",
      " 1.24060170e-06 9.12259839e-06 2.39469427e-05 4.47547827e-05\n",
      " 9.52544451e-06 3.17959674e-03 3.02218687e-05 4.30881017e-04\n",
      " 1.42304704e-01 2.80868699e-04 2.05219825e-04 1.30253914e-03\n",
      " 5.38144552e-04 9.64941282e-05 5.73405589e-04 1.37569441e-04\n",
      " 1.11582094e-05 2.13942694e-05 2.39796583e-02 2.74498598e-04\n",
      " 6.31501852e-03 6.96358038e-03 1.68743078e-04 1.49578074e-04\n",
      " 5.80078949e-06 6.94251003e-06 3.21175531e-02 1.87523142e-06\n",
      " 7.53472932e-06 7.67067974e-08 2.20514194e-04 1.69260195e-03\n",
      " 1.55681209e-03 4.52766562e-06 1.08493634e-06 4.48138118e-02\n",
      " 5.72448289e-06 1.99535978e-03 3.88471381e-06 4.19945836e-01\n",
      " 1.58371741e-03 1.81832656e-01 2.88020298e-02 9.31373332e-04\n",
      " 2.24105176e-02 8.08461482e-05 3.30172297e-05 1.14534545e-04\n",
      " 1.56391994e-04 2.53519131e-04 6.49824599e-03 1.82033091e-08\n",
      " 3.48839414e-04 6.60955436e-07 8.85341433e-05 1.53344648e-04\n",
      " 2.42336150e-02 1.11776194e-06 6.85518444e-06 8.85245441e-08\n",
      " 5.10178681e-04 3.92433094e-07 6.99424272e-05 1.27512135e-06\n",
      " 6.28367718e-03 2.44150965e-06 1.62411539e-04 8.81697633e-04\n",
      " 1.56561256e-07 2.77818290e-05 3.02678764e-05 5.61696083e-07\n",
      " 1.72385445e-03 2.24233661e-02 1.40721982e-04 1.80408149e-03]\n",
      "\n",
      "Dimension of the second image prediction:(100,)\n",
      "Sum of the coefficient of this vector prediction: 1.0\n",
      "The class with the highest probability: 63\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(testEntire_normalized)\n",
    "print(\"Result of the prediction for the second image: \\n\" + str(predictions[1]))\n",
    "print(\"\\nDimension of the second image prediction:\" + str(predictions[1].shape))\n",
    "print(\"Sum of the coefficient of this vector prediction: \" + str(np.sum(predictions[1])))\n",
    "print(\"The class with the highest probability: \" + str(np.argmax(predictions[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2d6637-3897-4b09-8e9f-6b15c95d0d0b",
   "metadata": {},
   "source": [
    "### Accuracy Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "790151ab-3eb7-4506-9765-ad20e3be6d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model 1: Test loss: 2.8213131427764893, Test accuracy: 0.3230000138282776\n",
      " Model 2: Test loss: 2.7572784423828125, Test accuracy: 0.33799999952316284\n",
      " Model 3: Test loss: 3.4235785007476807, Test accuracy: 0.32100000977516174\n"
     ]
    }
   ],
   "source": [
    "print(f' Model 1: Test loss: {test_loss1}, Test accuracy: {test_accuracy1}')\n",
    "print(f' Model 2: Test loss: {test_loss2}, Test accuracy: {test_accuracy2}')\n",
    "print(f' Model 3: Test loss: {test_loss3}, Test accuracy: {test_accuracy3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e0689c-3201-4657-8628-fbfd14828d78",
   "metadata": {},
   "source": [
    "Model 2 made the most correct predictions among the three models with around 34% of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c99131-fa6a-47f6-84c2-ccfe3c8d7094",
   "metadata": {},
   "source": [
    "### Benchmarking \n",
    "\n",
    "Here are the results of the benchmark models:  \n",
    "\r",
    "* \r\n",
    "Stochastic Pooling: Percentage correct 57.\n",
    "* %\r\n",
    "NiN (Network In Network): Percentage correct 64\n",
    "* 3%\r\n",
    "DSN (Deeply-Supervised Nets): Percentage correct 6\n",
    "* HD-CNN (Hierarchical Deep Convolutional Neural Network for Large Scale Visual Recognition): Percentage correct 67.4\n",
    "* Spectral Representations for Convolutional Neural Networks: Percentage correct 68.4\n",
    "* .4%\r\n",
    "Dspike (ResNet-18): Percentage correct 7\n",
    "* .24%\r\n",
    "WRN-28-8 (SAMix+DM): Percentage correct \n",
    "* 5.59%\r\n",
    "Dynamics 1 (Particle Swarm Optimization): Percentage correct\n",
    "* 87.48%\r\n",
    "Astroformer: Percentage correc  \n",
    "  \n",
    "As we can see my models have lower performance compared to the benchmark models. There are using more advanced architectures and training methods, which can explain their superior performance. Some models are using regularization or/and data augmentation method and other type of neural networks than CNN.t 93.36%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a237f3-aa6f-4f3a-9b9e-589f14a6b421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
